# Copy this file to .env and fill in your values
# NEVER commit your actual .env file!

# =============================================================================
# Backend Selection
# =============================================================================
# LLM Backend: "openai" | "vllm" | "ollama"
LLM_BACKEND=openai

# Embedding Backend: "openai" | "local" | "tei"
EMBEDDING_BACKEND=openai

# =============================================================================
# OpenAI Configuration (when using openai backend)
# =============================================================================
OPENAI_API_KEY=sk-your-key-here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_CHAT_MODEL=gpt-4o-mini

# =============================================================================
# vLLM Configuration (when using vllm backend)
# =============================================================================
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_MODEL=hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4

# =============================================================================
# Ollama Configuration (when using ollama backend)
# =============================================================================
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# =============================================================================
# Local Embedding Configuration (when using local backend)
# =============================================================================
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2

# =============================================================================
# TEI Configuration (when using tei backend)
# =============================================================================
TEI_BASE_URL=http://localhost:8080
TEI_MODEL=BAAI/bge-small-en-v1.5

# =============================================================================
# Application Configuration
# =============================================================================
CHROMA_DB_DIR=.chroma
LLM_CACHE_DIR=.llm_cache
LLM_CACHE_ENABLED=true
HR_AGGREGATE_MODE=disabled
HR_MASKED_ROWS_MODE=disabled
HOST=127.0.0.1
PORT=8000
