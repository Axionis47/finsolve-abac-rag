# FinSolve ABAC RAG (Simple Guide)

This project is an internal chatbot for a company (FinSolve). It answers questions using your documents and follows strict access rules. We use an ABAC policy (Attribute Based Access Control) and a RAG pipeline (Retrieval Augmented Generation).

If you just want to run and try, follow Quick Start below. Language is kept simple.

---

## What it can do
- Secure login (basic, for demo)
- Finds best information using:
  - Dense search (Chroma + OpenAI embeddings)
  - Sparse search (BM25)
  - Fusion of both (RRF)
  - Optional reranking (simple | OpenAI embedding | OpenAI LLM)
- Policy checks (PDP) on every item, so people only see what they are allowed
- Answers are generated by LLM only from allowed context and always have citations
- HR data endpoints with masking and aggregates (policy controlled)
- Observability: timings and a correlation ID per request
- Admin panel (for c_level) to check status and reindex

---

## Quick Start
Requirements:
- Python 3.10+
- pip
- (Optional) virtualenv
- OpenAI API key if you want dense index and live LLM responses

Steps:
1) Clone and go inside folder
```
 git clone <your repo url>
 cd finsolve-abac-rag
```
2) Create and activate virtual env (optional but recommended)
```
 python -m venv .venv
 source .venv/bin/activate   # Windows: .venv\Scripts\activate
```
3) Install packages
```
 pip install -e .
```
4) Set OpenAI key (for embeddings + LLM)
```
 export OPENAI_API_KEY=sk-...
```
You can also keep it in a `.env` file at project root like:
```
 OPENAI_API_KEY=sk-...
```
5) Run app
```
 uvicorn app.main:app --reload
```
6) Open your browser
- Go to: http://127.0.0.1:8000/
- Login when prompted (see Users below)

---

## Users and roles (demo)
- Tony / password123 → engineering
- Bruce / securepass → marketing
- Sam / financepass → finance
- Peter / pete123 → engineering
- Sid / sidpass123 → marketing
- Natasha / hrpass123 → hr
- Clark / chief → c_level (admin panel visible)

These are only for demo. In real life, use SSO/IdP.

---

## Using the app
- Type your question on the page and submit
- You can change Top K and select reranker
- You will get answer, citations, timings, and a correlation ID
- If you login as Clark (c_level), you can see Admin panel buttons:
  - Refresh Status: shows counts (sparse/dense) and OpenAI health
  - Reindex (sparse): build in-memory BM25 index
  - Reindex (dense): build Chroma index (needs OpenAI key)

---

## Endpoints (short)
- UI: GET `/`
- Chat: POST `/chat`
- Search: POST `/search/dense`, POST `/search/hybrid`
- HR: GET `/hr/rows`, `/hr/aggregate`, `/hr/rows_masked`
- Admin: POST `/admin/reindex`, POST `/admin/reindex_dense`, GET `/admin/status`

All endpoints require login. Some need specific roles (policy enforced).

---

## Configuration
- `OPENAI_API_KEY` → set this for embeddings + LLM
- `OPENAI_EMBEDDING_MODEL` (default: text-embedding-3-small)
- `OPENAI_CHAT_MODEL` (default: gpt-4o-mini)
- `CHROMA_DB_DIR` (default: .chroma)
- `HR_AGGREGATE_MODE` / `HR_MASKED_ROWS_MODE` → enable/disable features

You can put these in `.env`.

---

## Architecture & Policy
- Full document with diagram: `docs/ARCHITECTURE.md`
- Policy file: `docs/policy.yaml`

In short: We do hybrid retrieval, check PDP policy for every item, and then only pass allowed snippets to LLM. The LLM must answer only from given context and must cite sources.

---

## Testing
Run test suite:
```
 pytest -q
```
Tests use monkeypatching for external calls, so they are stable and do not need real network.

---


---

## E2E Retrieval Test Results (Live with OpenAI key)

These are quick end-to-end checks we ran locally using real embeddings and hybrid search. Language is simple and clear.

- How we tested
  - Endpoint: POST /search/hybrid (dense + sparse + policy)
  - OpenAI key set in env, dense search active
  - top_k = 3, no reranking (kept simple)

- Results
  1) Query: "marketing ROI 2024" as Bruce (marketing)
     - Sources came from marketing reports
     - Example: resources/data/marketing/market_report_q4_2024.md (Q4 overview)
     - Policy: allowed (same_department_internal_docs)
  2) Query: "Salary Structure" as Bruce (marketing)
     - Source: resources/data/general/employee_handbook.md (Salary Structure section)
     - Policy: allowed (general_docs_any_role)
  3) Query: "Q4 2024 revenue 2.6 billion" as Sam (finance)
     - Source: resources/data/finance/quarterly_financial_report.md (Q4 overview)
     - Policy: allowed (same_department_internal_docs)
  4) Query: "employee salary details" as Bruce (marketing)
     - Only general handbook sections returned (no HR CSV or HR-only docs)
     - Confirms policy blocking HR-only content for non-HR roles

- Performance (approx): dense_ms ~ 0.9–1.5s per query; total ~1.0–1.5s

- Conclusion
  - System is retrieving the right information from the correct documents
  - Policy (PDP) is working as expected for roles

## Common issues
- If chat works but quality is low: maybe dense index is empty. Login as `Clark/chief` and click “Reindex (dense)” in Admin panel (need `OPENAI_API_KEY`).
- If embeddings or LLM calls fail: check `OPENAI_API_KEY` and internet access.

---

